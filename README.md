# cain-2024-replication-package
This repository contains the replication package of the paper **The Impact of Knowledge Distillation on the Performance and Energy Consumption of NLP Models**, published at the International Conference on AI Engineering - Software Engineering for AI (CAIN 2024).

This study has been designed, developed and reported by the folllowing investigators:
- [Ye Yuan](mailto:y.yuan3@student.vu.nl) (Vrije Universiteit Amsterdam)
- [Eloise Zhang](mailto:j.zhang6@student.vu.nl) (Vrije Universiteit Amsterdam)
- [Zongyao Zhang](mailto:z.zhang14@student.vu.nl) (Vrije Universiteit Amsterdam)
- [Kaiwei Chen](mailto:k.chen2@student.vu.nl) (Vrije Universiteit Amsterdam)
- [Jiacheng Shi](mailto:j.shi2@student.vu.nl) (Vrije Universiteit Amsterdam)

For any information, interested researchers can contact us by sending an email to any of the investigators listed above.

## Structure of the replication package
This replication package is organized according to the following structure:
```
├── README.md: The file you are reading right now.
├── LICENSE: File describing under which license the content of this repository is being made available.
├── data                        Data used in the paper 
│   ├── experiment_data         Dataset generated from the experiment
│   ├── script                  Script for generating and visualizing the graphs from the dataset
│   └── plot                    Graphical representation of the results
├── documentation               Our paper detailing the experiment settings and results
└── src                         Source code and dependencies used in the paper
    └──script                   Code for executing the experiment
```

## How to cite this work
If the data or software contained in this replication package is helping your research, consider to cite it is as follows, thanks!

```
@inproceedings{
}
```
